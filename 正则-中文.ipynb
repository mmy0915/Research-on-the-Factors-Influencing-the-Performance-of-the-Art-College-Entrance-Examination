{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山海大学\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "'''\n",
    "python 3.5版本\n",
    "正则匹配中文，固定形式：\\u4E00-\\u9FA5\n",
    "'''\n",
    "\n",
    "words = 'study in 山海大学'\n",
    "regex_str = \".*?([\\u4E00-\\u9FA5]+大学)\"\n",
    "match_obj = re.match(regex_str, words)\n",
    "if match_obj:\n",
    "    print(match_obj.group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "心理箴言\n",
      "现实是污浊的河流\n",
      "要想接受污浊的河流而自身不被污染\n",
      "我们必须成为大海\n"
     ]
    }
   ],
   "source": [
    "str=u\"【心理箴言】现实是污浊的河流，要想接受污浊的河流而自身不被污染，我们必须成为大海。 ​​=-=4845/.?'​\"\n",
    "\n",
    "# py2.7，所以字符串前加u，在正则表达式前也加u即可。\n",
    "# pattern =re.compile(u'[\\u4e00-\\u9fa5]')\n",
    "pattern =re.compile(r\"[\\u4e00-\\u9fa5]+\")\n",
    "result=pattern.findall(str)\n",
    "result1=re.findall(pattern,str)\n",
    "for w in result:\n",
    "    print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['小', '明']\n"
     ]
    }
   ],
   "source": [
    "str1='hjggj小vjjk明'\n",
    "pat=re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "result=pat.findall(str1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['小明']\n"
     ]
    }
   ],
   "source": [
    "str2='小明'\n",
    "pat=re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "result=pat.findall(str2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['安', '', '徽', '', '一', '', '中', '']\n"
     ]
    }
   ],
   "source": [
    "str3='安 徽 一 中'\n",
    "pat=re.compile(r'[\\u4e00-\\u9fa5]*')\n",
    "result=pat.findall(str3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/^[\\u2E80-\\u9FFF]+$/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = difflib.Differ()\n",
    "diff = d.compare(text1_lines, text2_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff2 = difflib.unified_diff(\n",
    "    text1_lines,\n",
    "    text2_lines,\n",
    "    lineterm='',\n",
    ")\n",
    "print('\\n'.join(diff2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def show_results(match):\n",
    "    print('  a    = {}'.format(match.a))\n",
    "    print('  b    = {}'.format(match.b))\n",
    "    print('  size = {}'.format(match.size))\n",
    "    i, j, k = match\n",
    "    print('  A[a:a+size] = {!r}'.format(A[i:i + k]))\n",
    "    print('  B[b:b+size] = {!r}'.format(B[j:j + k]))\n",
    "\n",
    "\n",
    "A = \" abcd\"\n",
    "B = \"abcd abcd\"\n",
    "\n",
    "print('A = {!r}'.format(A))\n",
    "print('B = {!r}'.format(B))\n",
    "\n",
    "print('\\nWithout junk detection:')\n",
    "s1 = SequenceMatcher(None, A, B)\n",
    "match1 = s1.find_longest_match(0, len(A), 0, len(B))\n",
    "show_results(match1)\n",
    "\n",
    "print('\\nTreat spaces as junk:')\n",
    "s2 = SequenceMatcher(lambda x: x == \" \", A, B)\n",
    "match2 = s2.find_longest_match(0, len(A), 0, len(B))\n",
    "show_results(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s1 = [1, 2, 3, 5, 6, 4]\n",
    "s2 = [2, 3, 5, 4, 6, 1]\n",
    "\n",
    "print('Initial data:')\n",
    "print('s1 =', s1)\n",
    "print('s2 =', s2)\n",
    "print('s1 == s2:', s1 == s2)\n",
    "print()\n",
    "\n",
    "matcher = difflib.SequenceMatcher(None, s1, s2)\n",
    "for tag, i1, i2, j1, j2 in reversed(matcher.get_opcodes()):\n",
    "\n",
    "    if tag == 'delete':\n",
    "        print('Remove {} from positions [{}:{}]'.format(\n",
    "            s1[i1:i2], i1, i2))\n",
    "        print('  before =', s1)\n",
    "        del s1[i1:i2]\n",
    "\n",
    "    elif tag == 'equal':\n",
    "        print('s1[{}:{}] and s2[{}:{}] are the same'.format(\n",
    "            i1, i2, j1, j2))\n",
    "\n",
    "    elif tag == 'insert':\n",
    "        print('Insert {} from s2[{}:{}] into s1 at {}'.format(\n",
    "            s2[j1:j2], j1, j2, i1))\n",
    "        print('  before =', s1)\n",
    "        s1[i1:i2] = s2[j1:j2]\n",
    "\n",
    "    elif tag == 'replace':\n",
    "        print(('Replace {} from s1[{}:{}] '\n",
    "               'with {} from s2[{}:{}]').format(\n",
    "                   s1[i1:i2], i1, i2, s2[j1:j2], j1, j2))\n",
    "        print('  before =', s1)\n",
    "        s1[i1:i2] = s2[j1:j2]\n",
    "\n",
    "    print('   after =', s1, '\\n')\n",
    "\n",
    "print('s1 == s2:', s1 == s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words1 = '安徽省合肥市第一中学'\n",
    "words2 = '合肥一中'\n",
    "words3 = '合肥第一中学'\n",
    "words4 = '安徽合肥第一中学'\n",
    "words5 = '安徽合肥第三中学'\n",
    "\n",
    "regex_str = \".*?([\\u4E00-\\u9FA5]+一中).*\"\n",
    "match_obj1 = re.match(regex_str, words1)\n",
    "match_obj2 = re.match(regex_str, words2)\n",
    "match_obj3 = re.match(regex_str, words3)\n",
    "match_obj4 = re.match(regex_str, words4)\n",
    "match_obj5 = re.match(regex_str, words5)\n",
    "\n",
    "if match_obj1:\n",
    "    print(match_obj1.group(0))\n",
    "    \n",
    "if match_obj2:\n",
    "    print(match_obj2.group(0))\n",
    "    \n",
    "if match_obj3:\n",
    "    print(match_obj3.group(0))\n",
    "    \n",
    "if match_obj4:\n",
    "    print(match_obj4.group(0))\n",
    "    \n",
    "if match_obj5:\n",
    "    print(match_obj5.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_excel(\"Canteen.xlsx\") # 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出'Dept'这一列\n",
    "data2_Dept = data2['Dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       第一食堂\n",
       "1       第二食堂\n",
       "2       第二食堂\n",
       "3     好利来食品店\n",
       "4     好利来食品店\n",
       "5       第三食堂\n",
       "6       第三食堂\n",
       "7       第三食堂\n",
       "8        财务处\n",
       "9       第四食堂\n",
       "10      第四食堂\n",
       "11      第四食堂\n",
       "12      第四食堂\n",
       "13      第四食堂\n",
       "14      第四食堂\n",
       "15      第一食堂\n",
       "16      第一食堂\n",
       "17      第二食堂\n",
       "18      第二食堂\n",
       "19      第二食堂\n",
       "20      第二食堂\n",
       "21      第二食堂\n",
       "Name: Dept, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_Dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第二食堂      7\n",
      "第四食堂      6\n",
      "第三食堂      3\n",
      "第一食堂      3\n",
      "好利来食品店    2\n",
      "财务处       1\n",
      "Name: Dept, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 查看'Dept'这一列分类情v况  # 结果为有6个类别的食堂\n",
    "print(data2_Dept.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dept\n",
      "0   第一食堂\n",
      "1   第二食堂\n",
      "2   第二食堂\n",
      "15  第一食堂\n",
      "16  第一食堂\n",
      "17  第二食堂\n",
      "18  第二食堂\n",
      "19  第二食堂\n",
      "20  第二食堂\n",
      "21  第二食堂\n"
     ]
    }
   ],
   "source": [
    "# 取出'Dept'这一列所有食堂的行,构建新的DF: data_canteen\n",
    " \n",
    "data_canteen = data2[(data2['Dept']=='第一食堂') | (data2['Dept']=='第二食堂')][['Dept']]    \n",
    "# (data2['Dept']=='第一食堂') 表示提取出Dept列中'第一食堂'所在的所有行\n",
    "# (data2['Dept']=='第二食堂') 表示提取出Dept列中'第二食堂'所在的所有行\n",
    "# ['CardCount','Dept']表示Dept取出这一列\n",
    "# | 是逻辑符号: 或\n",
    " \n",
    "print(data_canteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"综合信息汇总（处理版）.xls\"\n",
    "df_total = pd.read_excel(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 毕业中学名称\n",
      "33      wang'jiang'xian\n",
      "47      wang'jiang'xian\n",
      "68      wang'jiang'xian\n",
      "131         安徽安庆碧桂园二中分校\n",
      "144            安徽安庆一中登云\n",
      "...                 ...\n",
      "113507             铸才中学\n",
      "113510        庄河市第三高级中学\n",
      "113518         淄博市第十一中学\n",
      "113610             紫阳中学\n",
      "113680        遵义市第一高级中学\n",
      "\n",
      "[4591 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "data_anhui = df_total[(df_total['毕业中学所在省']=='安徽省')][['毕业中学名称']]    \n",
    "# (data2['Dept']=='第一食堂') 表示提取出Dept列中'第一食堂'所在的所有行\n",
    "# (data2['Dept']=='第二食堂') 表示提取出Dept列中'第二食堂'所在的所有行\n",
    "# ['CardCount','Dept']表示Dept取出这一列\n",
    "# | 是逻辑符号: 或\n",
    " \n",
    "print(data_anhui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>毕业中学名称</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>合肥市第一中学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         毕业中学名称\n",
       "count      4591\n",
       "unique     1456\n",
       "top     合肥市第一中学\n",
       "freq         52"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_anhui.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "毕业中学名称    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_anhui.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_anhui = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fd264fb14685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_anhui\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlist_anhui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "for item in data_anhui:\n",
    "    list_anhui.append(str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "134",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 134",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-62cc246accb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_anhui\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m134\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 134"
     ]
    }
   ],
   "source": [
    "data_anhui[134].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
